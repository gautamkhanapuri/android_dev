brew search postgresql
brew formulae | grep postgresql
brew install postgresql@16

Add Aliases to stop and start postgresql
alias spg='brew services start postgresql@16'
alias cpg='ps -aef | grep postgres'
alias epg='brew services stop postgresql@16'
alias pgcl='/usr/local/opt/postgresql\@16/bin/psql -U postgres'

/usr/local/opt/postgresql\@16/bin/postgres --version
/usr/local/opt/postgresql\@16/bin/createdb testdb
/usr/local/opt/postgresql\@16/bin/dropdb testdb
/usr/local/opt/postgresql\@16/bin/createuser postgres


\connect postgres <ajeybk installed user>
CREATE USER user1 WITH PASSWORD 'password@321#';
GRANT ALL PRIVILEGES ON DATABASE testdb  TO user1;
GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO user1;
\dg
drop USER user1
\dg
# Change in app_init.py
# from
#  engine = create_engine('postgresql://user1:pwd%26321%23@localhost:5432/testdb')
# to
#  engine = create_engine('postgresql://user1:password%26321%23@localhost:5432/testdb')



\c testdb
\c postgres
CREATE USER user1 WITH PASSWORD 'password@321';   // Will fail as no role


\conninfo
\password ajeybk
\conninfo
\password postgres

\c postgres ajeybk
\conninfo

\q


ALTER USER postgres WITH PASSWORD 'newsuperpassword';
\password postgres

CREATE TABLE products (
       id SERIAL PRIMARY KEY,
       name VARCHAR(128),
       description VARCHAR(255),
       brand VARCHAR(128),
       category VARCHAR(64),
       price INT not NULL,
       currency VARCHAR(16),
       stock INT not NULL,
       ean BIGINT not NULL,
       color VARCHAR(32),
       size VARCHAR(16),
       availability VARCHAR(16),
       internalId INT not NULL
   );

curl 'https://drive.usercontent.google.com/download?id=1aZNLCVO0VoHmvPNvSC2teeFmZfiViE6u&export=download&authuser=0' -o products-1000.csv

COPY products(id,name,description,brand,category,price,currency,stock,ean,color,size,availability,internalid)
   FROM '/Users/ajeybk/projects/prancer/gak/systemdesign/qas/largetableset/products-100.csv'
   DELIMITER ','
   CSV HEADER;

# Products list by price in descending order limit to 10
select id, name, price from products order by price desc limit 10;

select MAX(price) as second_price from products where price < (select MAX(price) from products);


CREATE TABLE customers (
       id SERIAL PRIMARY KEY,
       customerId VARCHAR(32),
       firstName VARCHAR(64),
       lastName VARCHAR(64),
       company VARCHAR(64),
       city VARCHAR(64),
       country VARCHAR(64),
       phone1 VARCHAR(32),
       phone2 VARCHAR(32),
       email VARCHAR(64),
       subscription DATE,
       website VARCHAR(255)
   );

COPY customers(id, customerId, firstName, lastName, company, city, country, phone1, phone2, email, subscription, website)
   FROM '<path to this file>/customers-100.csv'
   DELIMITER ','
   CSV HEADER;

brew install  7zip
7zz x customers-1000000.zip

COPY customers(id, customerId, firstName, lastName, company, city, country, phone1, phone2, email, subscription, website)
   FROM '/Users/ajeybk/projects/prancer/gak/systemdesign/qas/largetableset/customers-1000000.csv'
   DELIMITER ','
   CSV HEADER;

CREATE TABLE users (
  id SERIAL PRIMARY KEY,
  name VARCHAR(255) NOT NULL,
  email VARCHAR(255) NOT NULL,
  age INT NOT NULL
);

# Dump Table Schema
/usr/local/opt/postgresql\@16/bin/pg_dump -t 'public.customers' --schema-only testdb


https://medium.com/technology-hits/database-queries-in-python-sqlalchemy-postgresql-e90afe0a06b4

https://github.com/datablist/sample-csv-files/tree/main?tab=readme-ov-file

python3 -m venv qryenv
source qryenv/bin/activate
pip install -U pip
pip install -r requirements.txt


python app.py


Source: Insta @coding_lyf

Q: Suppose you have 1 million records like Amazon which handles a massive number of products. 

S: Pagination with pagesize and other parameters as per implementation.

/products?offset=1000&pagesize=10
Why not offset pagination: Offset is to skip number of rows
   select * from products order by id  limit 10 offset 1000;

/products?key=0&pagesize=10
/products?key=10&pagesize=10
keyset pagination: retrieves records based on a specific key (usually unique and indexed column like id or timestamp). Faster than offset as indexed column fetch is log(n)
   select * from products where id > 10 order by id limit 10;

@measuretime
def get_products(offset=0, pagesize=10):
  # validate offset for integer and greater than zero
  # validate pagesize for positive integer and in multiples of 10
  return [] # Array of products

def get_products(key=0, pagesize=10):
  # validate key for integer and greater than zero
  # validate pagesize for positive integer and in multiples of 10
  return [] # Array of products

